{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"How to create your Chatbots with Telegram and AI Models","text":"<p>This workshop guides participants through building a chatbot for a hair salon using Telegram and AI models like OpenAI and Ollama. It focuses on integrating large language models (LLMs) with the Vercel SDK AI to create an intelligent bot that can handle appointment bookings. The workshop is organized by the Aula de Software Libre de la University of Cordoba.</p> <p>Template</p> <p>There is a template that includes the template. If you wish you can use it to have the system exactly configured as we have it in the tutorial.</p> <p>The template can also be run directly in Codespaces in case you want to start working.</p> <p>You can clone the template from the repository web: https://github.com/aulasoftwarelibre/workshop-telegram-bots-with-ai-template</p> <p>Or open it directly by clicking here:</p> <p></p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>This workshop has been given by the following people:</p> <ul> <li>Sergio Gomez</li> </ul>"},{"location":"#license","title":"License","text":"<p>The material is published under license Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)</p>"},{"location":"agents/basic/","title":"Understanding Agents","text":"<p>In the context of AI and chatbots, agents are \"intelligent\" entities designed to perform tasks autonomously or semi-autonomously. They leverage tools and function calling to enhance their capabilities, allowing them to interact with users and perform complex operations efficiently.</p>"},{"location":"agents/basic/#what-are-agents","title":"What are Agents?","text":"<p>Agents can be thought of as specialized programs that respond to user inputs or environmental stimuli. They possess certain characteristics:</p> <ul> <li>Autonomy: Agents can operate without direct human intervention, making decisions based on predefined logic or learned behaviors.</li> <li>Reactivity: They can respond to changes in their environment, allowing them to adapt their behavior based on real-time information.</li> <li>Proactivity: Some agents can take initiative, anticipating user needs or system requirements and acting accordingly.</li> </ul>"},{"location":"agents/basic/#tools-and-function-calling","title":"Tools and Function Calling","text":"<p>Agents utilize tools and function calling mechanisms to perform specific tasks. These tools can be thought of as functions or APIs that agents can invoke to achieve their objectives. Here are some key concepts:</p>"},{"location":"agents/basic/#tools","title":"Tools","text":"<ul> <li>Definition: Tools are pre-defined functions or APIs that agents can access to carry out specific operations. They provide agents with the ability to interact with external systems, databases, or services.</li> <li>Examples: Common tools include APIs for fetching data, processing transactions, sending notifications, and more. In chatbot scenarios, tools might also include integrations with platforms like Google Calendar for scheduling or payment gateways for processing transactions.</li> </ul>"},{"location":"agents/basic/#function-calling","title":"Function Calling","text":"<ul> <li>Definition: Function calling refers to the mechanism by which agents invoke tools to perform tasks. This can involve sending requests, handling responses, and processing the results.</li> <li>Process: </li> <li>Identify: The agent identifies a need or task that requires external assistance.</li> <li>Invoke: The agent calls the appropriate function/tool to fulfill the request.</li> <li>Receive Response: The agent waits for a response from the tool, which may include data or confirmation of the completed task.</li> <li>Act: Based on the response, the agent takes further actions, such as updating a user or executing additional tasks.</li> </ul>"},{"location":"agents/basic/#conclusion","title":"Conclusion","text":"<p>Agents, equipped with tools and the ability to call functions, provide a powerful means of enhancing user interaction and automating processes. By leveraging these capabilities, agents can deliver more responsive and intelligent services, ultimately improving the overall user experience.</p>"},{"location":"agents/using-tools-2/","title":"Handling User Selection","text":"<p>In this chapter, we\u2019ll focus on how the chatbot processes user selections of time slots and finalizes their booking by reserving the appointment in the database. We\u2019ll examine how the user\u2019s button action triggers the confirmation tool and how the appointment is stored and managed.</p>"},{"location":"agents/using-tools-2/#processing-user-selections-and-confirming-the-appointment","title":"Processing User Selections and Confirming the Appointment","text":"<p>Once the user has chosen a time slot using the button interface, the chatbot must handle this selection and confirm the booking. This process involves handling the button action, reserving the time slot, and providing feedback to the user.</p>"},{"location":"agents/using-tools-2/#managing-appointment-data","title":"Managing Appointment Data","text":"<p>The AppointmentRepository is responsible for handling appointment data within our chatbot. It ensures that available time slots are fetched, new ones are created if necessary, and appointments are reserved when a user confirms a time slot.</p> <p>The <code>reserve</code> is a new function than attempts to reserve an available slot. It updates the database, associating the selected time slot with the user\u2019s chat ID. If successful, the slot is marked as reserved, and no other users can select it.</p> src/lib/repositories/appointments.ts<pre><code>import { and, eq, isNull } from \"drizzle-orm/expressions\";\n\nimport { db as database } from \"../db/index\";\nimport { appointments } from \"../db/schema/appointments\";\n\nexport class AppointmentRepository {\n  async getFreeAppointmentsForDay(date: Date): Promise&lt;Array&lt;{ timeSlot: string }&gt;&gt; {\n    const allAppointments = await database\n      .select({\n        chatId: appointments.chatId,\n        timeSlot: appointments.timeSlot,\n      })\n      .from(appointments)\n      .where(eq(appointments.date, date));\n\n    // If no appointments exist for this day, create them\n    if (allAppointments.length === 0) {\n      await this.createEmptyAppointmentsForDay(date);\n      return this.getFreeAppointmentsForDay(date);\n    }\n\n    // Filter free appointments where chatId is null (not reserved)\n    const freeAppointments = allAppointments.filter((appointment) =&gt; appointment.chatId === null);\n\n    return freeAppointments.map((appointment) =&gt; ({\n      timeSlot: appointment.timeSlot,\n    }));\n  }\n\n  private async createEmptyAppointmentsForDay(date: Date): Promise&lt;void&gt; {\n    const openingTime = 9; // 9 AM\n    const closingTime = 19; // 7 PM\n\n    const timeSlots = Array.from({ length: closingTime - openingTime }, (_, index) =&gt; {\n      const time = `${(openingTime + index).toString().padStart(2, \"0\")}:00`;\n      return { date, timeSlot: time };\n    });\n\n    // Insert empty appointments for each time slot\n    await database.insert(appointments).values(timeSlots);\n  }\n\n  async reserve(chatId: number, date: Date, timeSlot: string): Promise&lt;boolean&gt; {\n    const updated = await database\n      .update(appointments)\n      .set({ chatId })\n      .where(and(eq(appointments.date, date), eq(appointments.timeSlot, timeSlot), isNull(appointments.chatId)))\n      .returning()\n      .execute();\n\n    return updated.length &gt; 0;\n  }\n}\n\nexport const appointmentsRepository = new AppointmentRepository();\n</code></pre>"},{"location":"agents/using-tools-2/#confirming-the-appointment","title":"Confirming the Appointment","text":"<p>The <code>confirmAppointment</code> tool is used to handle the reservation once the user selects a time slot. The tool checks if the selected time slot is still available in the database. If the slot is free, it reserves it for the user by associating it with their chat ID. If the slot is already taken, it notifies the user that they need to pick a different time. This tool ensures that only available slots can be reserved, and it provides feedback based on the reservation\u2019s success or failure.</p> src/lib/tools/confirm-appointment.ts<pre><code>import { type CoreTool, tool } from \"ai\";\nimport type { Context } from \"grammy\";\nimport { z } from \"zod\";\n\nimport { appointmentsRepository } from \"../repositories/appointments\";\nimport { tomorrow } from \"../utils\";\n\nexport const buildConfirmAppointment = (context: Context): CoreTool =&gt;\n  tool({\n    description: \"Confirm the selected appointment.\",\n    execute: async ({ slot }) =&gt; {\n      console.log(`Called confirmAppointment tool with ${JSON.stringify({ slot }, null, 2)}`);\n\n      const chatId = context.chatId;\n      if (!chatId) {\n        return \"Sorry, I cannot do the reserve.\";\n      }\n\n      const isReserved = appointmentsRepository.reserve(chatId, tomorrow(), slot);\n\n      if (!isReserved) {\n        return \"Sorry, that time slot is no longer available. Please choose another one.\";\n      }\n\n      return `Your appointment at ${slot} is confirmed!`;\n    },\n    parameters: z.object({\n      slot: z.string().describe(\"The selected time slot to confirm. Format HH:MM\"),\n    }),\n  });\n</code></pre>"},{"location":"agents/using-tools-2/#telegram-callback-listener-for-button-actions","title":"Telegram Callback Listener for Button Actions","text":"<p>The onAppointment listener is responsible for capturing the user\u2019s button presses and processing them within the ongoing conversation. When a user clicks a time slot button, the listener extracts the selected slot from the button\u2019s callback data and integrates it into the conversation.</p> src/lib/handlers/on-appointment.ts<pre><code>import { generateText } from 'ai'\nimport { Composer } from 'grammy'\n\nimport { registry } from '../ai/setup-registry'\nimport { environment } from '../environment.mjs'\nimport { conversationRepository } from '../repositories/conversation'\nimport { buildConfirmAppointment } from '../tools/confirm-appointment'\n\nexport const onAppointment = new Composer()\n\nconst PROMPT = `\nYou are a chatbot designed to help users book hair salon appointments for tomorrow.\nYou have access to several tools to help with this task and are restricted to handling appointment bookings only. You do not handle any other inquiries.\nYour primary goal is to guide users through the process of booking their appointments efficiently.\n\nYou will follow these rules:\n\n1. Appointment Search: Use the \"getFreeAppointments\" tool to search for available appointment times for tomorrow.\n2. Display Options: After \"getFreeAppointments\" use always the \"displaySelectionButtons\" tool to ask the user the available time slots as buttons they can select from.\n3. Confirm Appointment: After the user selects a time, use the confirmAppointment function to finalize their appointment request.\n4. Single-purpose chatbot: You only help users book appointments for tomorrow and do not answer unrelated questions, you need to use tools to ask options.\n\nIf a user asks for information outside of these details, please respond with: \"I'm sorry, but I cannot assist with that. For more information, please call us at (555) 456-7890 or email us at info@hairsalon.com.\"\n`\n\nonAppointment.callbackQuery(/slot-.+/, async (context) =&gt; {\n  const chatId = context.chatId as number\n  const slot = context.callbackQuery.data.slice(5)\n\n  await conversationRepository.addMessage(chatId, {\n    content: slot,\n    role: 'user',\n  })\n  const messages = await conversationRepository.get(chatId)\n\n  await context.api.sendChatAction(chatId, 'typing')\n\n  const { responseMessages, text } = await generateText({\n    maxSteps: 2,\n    messages,\n    model: registry.languageModel(environment.MODEL),\n    system: PROMPT,\n    tools: {\n      confirmAppointment: buildConfirmAppointment(context),\n    },\n  })\n\n  // Store the assistant's response\n  for await (const message of responseMessages) {\n    await conversationRepository.addMessage(chatId, message)\n  }\n\n  if (!text) {\n    return\n  }\n\n  // Reply with the generated text\n  await context.reply(text)\n})\n</code></pre> <p>And we need include this listener into the main bot file:</p> src/main.ts<pre><code>import process from 'node:process'\n\nimport { Bot } from 'grammy'\n\nimport { ask } from './lib/commands/ask'\nimport { learn } from './lib/commands/learn'\nimport { start } from './lib/commands/start'\nimport { environment } from './lib/environment.mjs'\nimport { onAppointment } from './lib/handlers/on-appointment'\nimport { onMessage } from './lib/handlers/on-message'\n\nasync function main(): Promise&lt;void&gt; {\n  const bot = new Bot(environment.BOT_TOKEN)\n\n  bot.command('start', start)\n  bot.command('learn', learn)\n  bot.command('ask', ask)\n\n  bot.use(onMessage)\n  bot.use(onAppointment)\n\n  // Enable graceful stop\n  process.once('SIGINT', () =&gt; bot.stop())\n  process.once('SIGTERM', () =&gt; bot.stop())\n  process.once('SIGUSR2', () =&gt; bot.stop())\n\n  await bot.start()\n}\n\nmain().catch((error) =&gt; console.error(error))\n</code></pre>"},{"location":"agents/using-tools/","title":"Displaying Available Time Slots","text":"<p>In this chapter, we\u2019ll explore how our chatbot guides users to book a hair salon appointment for the next day by displaying the available time slots using Telegram buttons. We will focus on retrieving the available appointments and dynamically creating button options for the user.</p>"},{"location":"agents/using-tools/#showing-time-slot-buttons-to-users","title":"Showing Time Slot Buttons to Users","text":"<p>Our chatbot uses several components to display time slot buttons, allowing users to easily select their preferred appointment time. We\u2019ll break down how this is achieved by combining the Telegram bot API, the Vercel AI SDK, and custom tools.</p> <p>The chatbot leverages tools from the Vercel AI SDK to perform specific actions\u2014like displaying buttons. In this case, the displaySelectionButtons tool is responsible for rendering Telegram buttons for available time slots. This tool works with the context provided by Telegram (via grammy), dynamically creating and sending button options to the user.</p> <p>The chatbot uses the getFreeAppointments tool to retrieve available time slots for the next day. This tool queries the backend for any unreserved time slots. The slots are passed into the displaySelectionButtons tool, which then turns them into clickable options for the user to choose from.</p> <p>The Telegram API, through grammy, allows the chatbot to interact with users in a conversational manner. Once the chatbot receives a message from the user, it generates a response using the AI model from Vercel, following the set rules in the prompt. If time slots are available, the bot uses InlineKeyboard to display them as buttons, providing a seamless way for users to select their appointment time.</p> <p>To maintain a coherent flow, the chatbot uses the conversationRepository to log user messages and the bot\u2019s responses. This ensures the chatbot can maintain context, such as remembering which time slots were offered, and guiding the user step-by-step toward confirming their appointment.</p> <p>By combining these components, the chatbot provides a smooth and user-friendly booking experience. In the next chapter, we will cover how to handle the button clicks and confirm the reservation.</p>"},{"location":"agents/using-tools/#create-the-tool-to-display-buttons","title":"Create the tool to display buttons","text":"src/lib/tools/display-selection-buttons.ts<pre><code>import { type CoreTool, tool } from 'ai'\nimport { type Context, InlineKeyboard } from 'grammy'\nimport { z } from 'zod'\n\nexport const buildDisplaySelectionButtons = (context: Context): CoreTool =&gt;\n  tool({\n    description:\n      'Use this tool to ask to the user with the available time slots as buttons they can select from.',\n    execute: async ({ options, question }) =&gt; {\n      console.log(\n        `Called displaySelectionButtons tool with ${JSON.stringify({ options, question }, null, 2)}`,\n      )\n\n      const buttonsRows = []\n      for (let index = 0; index &lt; options.length; index += 2) {\n        buttonsRows.push(\n          options\n            .slice(index, index + 2)\n            .map((option: string) =&gt; ({\n              data: `slot-${option}`,\n              label: option,\n            }))\n            .map(({ data, label }) =&gt; InlineKeyboard.text(label, data)),\n        )\n      }\n\n      await context.reply(question, {\n        reply_markup: InlineKeyboard.from(buttonsRows),\n      })\n\n      return null\n    },\n    parameters: z.object({\n      options: z\n        .array(z.string())\n        .describe('Array of time slots for the user to choose from'),\n      question: z.string().describe('The question to ask the user'),\n    }),\n  })\n</code></pre>"},{"location":"agents/using-tools/#add-the-tool-and-update-the-prompt","title":"Add the tool and update the prompt","text":"src/lib/handlers/on-message.ts<pre><code>import { generateText } from 'ai'\nimport { Composer } from 'grammy'\n\nimport { registry } from '../ai/setup-registry'\nimport { environment } from '../environment.mjs'\nimport { conversationRepository } from '../repositories/conversation'\nimport { buildDisplaySelectionButtons } from '../tools/display-selection-buttons'\nimport { buildGetFreeAppointments } from '../tools/get-free-appointments'\n\nexport const onMessage = new Composer()\n\nconst PROMPT = `\nYou are a chatbot designed to help users book hair salon appointments for tomorrow.\nYou have access to several tools to help with this task and are restricted to handling appointment bookings only. You do not handle any other inquiries.\nYour primary goal is to guide users through the process of booking their appointments efficiently.\n\nYou will follow these rules:\n\n1. Appointment Search: Use the \"getFreeAppointments\" tool to search for available appointment times for tomorrow.\n2. Display Options: After \"getFreeAppointments\" use always the \"displaySelectionButtons\" tool to ask the user the available time slots as buttons they can select from.\n3. Confirm Appointment: After the user selects a time, use the confirmAppointment function to finalize their appointment request.\n4. Single-purpose chatbot: You only help users book appointments for tomorrow and do not answer unrelated questions, you need to use tools to ask options.\n\nIf a user asks for information outside of these details, please respond with: \"I'm sorry, but I cannot assist with that. For more information, please call us at (555) 456-7890 or email us at info@hairsalon.com.\"\n`\n\nonMessage.on('message:text', async (context) =&gt; {\n  const userMessage = context.message.text\n  const chatId = context.chat.id\n\n  // Store the user's message\n  await conversationRepository.addMessage(chatId, {\n    content: userMessage,\n    role: 'user',\n  })\n\n  // Retrieve past conversation history\n  const messages = await conversationRepository.get(chatId)\n\n  // Generate the assistant's response using the conversation history\n  const { responseMessages, text } = await generateText({\n    maxSteps: 2,\n    messages,\n    model: registry.languageModel(environment.MODEL),\n    system: PROMPT,\n    tools: {\n      displaySelectionButtons: buildDisplaySelectionButtons(context),\n      getFreeAppointments: buildGetFreeAppointments(),\n    },\n  })\n\n  // Store the assistant's response\n  for await (const message of responseMessages) {\n    await conversationRepository.addMessage(chatId, message)\n  }\n\n  if (!text) {\n    return\n  }\n\n  // Reply with the generated text\n  await context.reply(text)\n})\n</code></pre> <p>Now try to ask for an appointment and you will see how both tools are called in a row.</p>"},{"location":"bot/cloning/","title":"Workshop Telegram Bots with AI Template","text":"<p>This repository serves as a template for creating Telegram bots that leverage AI. You can quickly set up a development environment using GitHub Codespaces or run it locally using Docker.</p>"},{"location":"bot/cloning/#getting-started","title":"Getting Started","text":""},{"location":"bot/cloning/#using-this-template","title":"Using This Template","text":"<p>To get started with the project, you can create your own copy of this template repository. Follow these steps:</p> <ol> <li>Go to the workshop-telegram-bots-with-ai-template repository.</li> <li>Click on the Use this template button located at the top right corner of the page.</li> <li>Select your account or organization and provide a name for your new repository.</li> <li>Click Create repository from template.</li> </ol>"},{"location":"bot/cloning/#setting-up-with-github-codespaces","title":"Setting Up with GitHub Codespaces","text":"<p>This repository is configured with a devcontainer, which allows you to easily develop in a consistent environment. To use GitHub Codespaces:</p> <ol> <li>Once you have created your repository, navigate to it.</li> <li>Click on the Code button and then select Open with Codespaces.</li> <li>Click on New codespace to launch your development environment.</li> </ol> <p>The devcontainer configuration will automatically run <code>pnpm install</code> to install the necessary dependencies.</p>"},{"location":"bot/cloning/#running-locally","title":"Running Locally","text":"<p>If you prefer to run the project locally, you'll need to set up Docker and Visual Studio Code (VSCode) with the necessary extensions.</p>"},{"location":"bot/cloning/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker: Make sure Docker is installed and running on your machine. You can download it from Docker's official website.</li> <li>Visual Studio Code: Download and install VSCode from Visual Studio Code's official website.</li> <li>Dev Containers Extension: Install the Dev Containers extension for VSCode.</li> </ul>"},{"location":"bot/cloning/#steps-to-run-locally","title":"Steps to Run Locally","text":"<ol> <li>Clone your repository to your local machine:    <pre><code>git clone https://github.com/your-username/your-repository-name.git\ncd your-repository-name\n</code></pre></li> <li>Open the cloned repository in VSCode.</li> <li>When prompted, select Reopen in Container. This will build the Docker container defined in the .devcontainer folder.</li> </ol>"},{"location":"bot/create-bot/","title":"Creating a Telegram Bot with BotFather","text":""},{"location":"bot/create-bot/#introduction","title":"Introduction","text":"<p>In this guide, you'll learn how to create a Telegram bot using BotFather, the official Telegram bot for managing other bots. You'll set up your bot and get the necessary token to start developing your bot.</p>"},{"location":"bot/create-bot/#prerequisites","title":"Prerequisites","text":"<ul> <li>A Telegram account.</li> <li>The Telegram app installed on your device or access to Telegram Web.</li> </ul>"},{"location":"bot/create-bot/#steps-to-create-a-bot","title":"Steps to Create a Bot","text":""},{"location":"bot/create-bot/#step-1-start-a-chat-with-botfather","title":"Step 1: Start a Chat with BotFather","text":"<ol> <li>Open the Telegram app or website.</li> <li>Search for BotFather or navigate to t.me/botfather.</li> <li>Click on the Start button or send <code>/start</code> to initiate a conversation with BotFather.</li> </ol>"},{"location":"bot/create-bot/#step-2-create-a-new-bot","title":"Step 2: Create a New Bot","text":"<ol> <li>Send the command <code>/newbot</code> to BotFather.</li> <li>BotFather will prompt you to choose a name for your bot. The name can be anything you like.</li> <li>Next, you will need to select a username for your bot. The username must end with the word \"bot\" (e.g., <code>examplebot</code>). </li> </ol>"},{"location":"bot/create-bot/#step-3-get-your-bot-token","title":"Step 3: Get Your Bot Token","text":"<p>After successfully creating your bot, BotFather will provide you with a token. This token is important as it will be used to authenticate your bot and connect it to the Telegram API.</p> <ul> <li> <p>Example response from BotFather:</p> <pre><code>Done! Congratulations on your new bot. You will find it at t.me/examplebot.\nYou can now add a description, about section, and profile picture for your bot.\nUse this token to access the HTTP API:\n123456789:ABCDEFGHIJKLMNOPQRSTUVWXYZ\n</code></pre> </li> </ul> <p>You have successfully created a Telegram bot using BotFather! For further development, check the Telegram Bot API documentation.</p>"},{"location":"bot/create-bot/#additional-resources","title":"Additional Resources","text":"<ul> <li>Telegram Bot API Documentation</li> <li>Telegram Bot Developers Guide</li> </ul>"},{"location":"bot/running/","title":"Running an Echo Bot","text":"<p>In this section, we will go through how to run a basic echo bot using the Grammy library. This bot listens for messages from users and replies with the same message.</p>"},{"location":"bot/running/#setting-up-the-echo-bot","title":"Setting up the Echo Bot","text":"<p>The following code sets up a simple bot that echoes back any text message it receives.</p>"},{"location":"bot/running/#step-1-add-a-command","title":"Step 1: Add a command","text":"<p>The first step involves creating a simple <code>/start</code> command. This command responds with a welcome message to introduce the bot and let users know it\u2019s ready to help. It\u2019s a good practice to include a starting point like this for bots to guide the user experience, especially for first-time users.</p> src/lib/commands/start.ts<pre><code>import type { CommandContext, Context } from 'grammy'\n\nexport async function start(context: CommandContext&lt;Context&gt;): Promise&lt;void&gt; {\n  const content = 'Welcome, how can I help you?'\n  await context.reply(content)\n}\n</code></pre>"},{"location":"bot/running/#step-2-handle-messages","title":"Step 2: Handle Messages","text":"<p>This is where the echo functionality comes into play. The bot listens for incoming text messages from users and, upon receiving a message, responds by sending back the same message. This demonstrates the basic capability of the bot to handle and reply to user input.</p> src/lib/handlers/on-message.ts<pre><code>import { Composer } from 'grammy'\n\nexport const onMessage = new Composer()\n\nonMessage.on('message:text', async (context) =&gt; {\n  const userMessage = context.message.text\n  await context.reply(userMessage)\n})\n</code></pre>"},{"location":"bot/running/#step-3-construct-the-bot","title":"Step 3: Construct the bot","text":"<p>This section walks through setting up the core bot functionality. First, we initialize the bot using the token from environment variables, which is required for Telegram to authenticate and interact with your bot.</p> <p>Next, we attach the <code>/start</code> command and the echo message handler (<code>onMessage</code>). The bot listens for incoming text and command events and processes them accordingly.</p> <p>Additionally, we ensure the bot shuts down properly when the process receives termination signals, such as SIGINT or SIGTERM, making the bot more robust and production-ready.</p> src/main.ts<pre><code>import process from 'node:process'\n\nimport { Bot } from 'grammy'\n\nimport { start } from './lib/commands/start'\nimport { environment } from './lib/environment.mjs'\nimport { onMessage } from './lib/handlers/on-message'\n\nasync function main(): Promise&lt;void&gt; {\n  const bot = new Bot(environment.BOT_TOKEN)\n\n  bot.command('start', start)\n\n  bot.use(onMessage)\n\n  // Enable graceful stop\n  process.once('SIGINT', () =&gt; bot.stop())\n  process.once('SIGTERM', () =&gt; bot.stop())\n  process.once('SIGUSR2', () =&gt; bot.stop())\n\n  await bot.start()\n}\n\nmain().catch((error) =&gt; console.error(error))\n</code></pre>"},{"location":"bot/running/#running-the-bot","title":"Running the Bot","text":"<p>This final section provides a step-by-step guide on how to set up and run the bot. It includes copying environment variables, updating the configuration with the correct Telegram bot token, installing the required dependencies, and finally running the bot in development mode.</p> <ol> <li> <p>Copy the environment configuration:    Rename the provided <code>.env.example</code> file to <code>.env</code> to set up your environment variables. You can do this using the following command:     <pre><code>cp .env.example .env\n</code></pre></p> </li> <li> <p>Update the <code>.env</code> file:    Open the <code>.env</code> file and set the required environment variables, especially the <code>BOT_TOKEN</code> with your Telegram bot token:     <pre><code>BOT_TOKEN=your-telegram-bot-token\n</code></pre></p> </li> <li> <p>Install dependencies:    Make sure the required packages are installed by running:     <pre><code>pnpm install\n</code></pre></p> <p>Info</p> <p>This step was done automatically if you are using our devcontainer.</p> </li> <li> <p>Run the bot:    Start the bot in development mode:     <pre><code>pnpm run dev\n</code></pre></p> </li> </ol> <p>After following these steps, your bot will be running, and you can start chatting with it. The bot will respond to the <code>/start</code> command with a welcome message and echo any text message you send.</p>"},{"location":"chatbot/basic/","title":"Basic Chatbot with AI","text":"<p>In this chapter, we will integrate AI-powered responses into a basic chatbot. The chatbot uses an AI model to generate replies based on user input.</p>"},{"location":"chatbot/basic/#ai-powered-responses","title":"AI-Powered Responses","text":"<p>The chatbot relies on the <code>generateText</code> from Vercel SDK AI function to produce intelligent responses. This function takes two key inputs: the user\u2019s message (prompt) and system instructions that define the AI\u2019s role.</p>"},{"location":"chatbot/basic/#understanding-the-code","title":"Understanding the Code","text":"<p>When a user sends a message to the chatbot, the following code generates a response using the AI model:</p> <pre><code>const { text } = await generateText({\n    model: registry.languageModel(environment.MODEL),\n    prompt: userMessage,\n    system:\n    'You are a chatbot designed to help users book hair salon appointments for the next day.',\n})\n</code></pre>"},{"location":"chatbot/basic/#parameters","title":"Parameters","text":"<ol> <li> <p>model:    This line retrieves the AI model specified in the environment configuration (<code>environment.MODEL</code>). The <code>registry.languageModel</code> function is used to select the appropriate model from the registry, which contains providers like OpenAI or Ollama. In this case, the model is used to generate responses based on the user\u2019s input.</p> </li> <li> <p>prompt:    The <code>prompt</code> is the actual input message that the user has sent to the bot. It will be passed to the AI model so that it can generate an appropriate response. In this case, the user's message is stored in the <code>userMessage</code> variable.</p> </li> <li> <p>system:    The <code>system</code> field provides instructions to the AI model about how it should behave. This message ensures that the chatbot behaves like a virtual assistant specifically designed to help users book hair salon appointments. This is a way of giving the model context for its responses.</p> </li> </ol>"},{"location":"chatbot/basic/#how-it-works","title":"How It Works","text":"<ol> <li>The user sends a message to the chatbot.</li> <li>The <code>generateText</code> function takes the user\u2019s message (<code>prompt</code>) and uses the model specified by <code>environment.MODEL</code>.</li> <li>The system prompt ensures that the AI model knows it is a chatbot for booking appointments, guiding it to provide relevant responses.</li> <li>The AI model processes the input and generates a response, which is then sent back to the user.</li> </ol> <p>At this stage, the bot can respond intelligently using AI but lacks conversation memory to handle ongoing interactions.</p>"},{"location":"chatbot/basic/#full-code","title":"Full code","text":"<p>Example</p> <p>Update the next file to add the integration with the Vercel SDK AI</p> src/lib/handlers/on-message.ts<pre><code>import { generateText } from 'ai'\nimport { Composer } from 'grammy'\n\nimport { registry } from '../ai/setup-registry'\nimport { environment } from '../environment.mjs'\n\nexport const onMessage = new Composer()\n\nconst PROMPT = `\nYou are a chatbot designed to help users book hair salon appointments for the next day.\n`\n\nonMessage.on('message:text', async (context) =&gt; {\n  const userMessage = context.message.text\n\n  // Generate the assistant's response using the conversation history\n  const { text } = await generateText({\n    model: registry.languageModel(environment.MODEL),\n    prompt: userMessage,\n    system: PROMPT,\n  })\n\n  // Reply with the generated text\n  await context.reply(text)\n})\n</code></pre>"},{"location":"chatbot/memory/","title":"Adding Memory to the Bot","text":"<p>In this chapter, we will add memory to our chatbot by storing messages exchanged between the bot and the users. This is useful when we want the bot to reference past interactions to provide a better conversational experience. We will use Drizzle ORM to manage our database schema and PostgreSQL as our database.</p>"},{"location":"chatbot/memory/#step-1-creating-the-messages-table","title":"Step 1: Creating the Messages Table","text":"<p>We will create a table named <code>messages</code> to store the conversations. </p>"},{"location":"chatbot/memory/#example-table-structure","title":"Example Table Structure","text":"<p>To create this table using Drizzle ORM, we can follow a similar structure to other tables created in the project. Below is a basic template:</p> src/lib/db/schema/messages.ts<pre><code>import { bigint, jsonb, pgTable, serial, timestamp } from 'drizzle-orm/pg-core'\n\nexport const messages = pgTable('messages', {\n  chatId: bigint({ mode: 'number' }).notNull(),\n  content: jsonb('content').notNull(),\n  messageId: serial('message_id').primaryKey(),\n  occurredOn: timestamp('occurred_on').defaultNow().notNull(),\n})\n</code></pre>"},{"location":"chatbot/memory/#fields-breakdown","title":"Fields Breakdown","text":"<ul> <li>messageId: Auto-incrementing primary key for each message.</li> <li>chatId: This stores the unique identifier of the chat session.</li> <li>content: Contains the structured JSON data of the message, typically formatted as a <code>CoreMessage</code> from the Vercel SDK.</li> <li>occurredOn: Automatically set timestamp for when the message was created.</li> </ul> <p>Info</p> <p>For this project, this information is enough, but in other cases you may need to create a separate chat table or create another table for the user and store other data. </p>"},{"location":"chatbot/memory/#step-2-running-migrations","title":"Step 2: Running Migrations","text":"<p>Once you have defined your table, you will need to generate the migration and run it in your PostgreSQL database.</p>"},{"location":"chatbot/memory/#generating-and-applying-the-migration","title":"Generating and Applying the Migration","text":"<p>To generate the migration file, run:</p> <pre><code>pnpm db:generate\n</code></pre> <p>This will generate the migration file based on your schema.</p> <p>Next, run the migration to update your database schema:</p> <pre><code>pnpm db:migrate\n</code></pre> <p>This will apply the migration and create the <code>messages</code> table in your database.</p>"},{"location":"chatbot/memory/#step-3-storing-and-retrieving-messages","title":"Step 3: Storing and Retrieving Messages","text":"<p>Once the table is set up, you can integrate your bot to store messages in the <code>messages</code> table whenever a user sends a message or the bot replies. This will allow you to build memory features for your bot, improving its ability to reference past conversations. To do that we are going to create this repository class:</p> src/lib/repositories/conversation.ts<pre><code>import type { CoreMessage } from 'ai'\nimport { asc, eq } from 'drizzle-orm/expressions'\n\nimport { db as database } from '../db/index'\nimport { messages } from '../db/schema/messages'\n\nexport class ConversationRepository {\n  async get(chatId: number): Promise&lt;CoreMessage[]&gt; {\n    const result = await database\n      .select({\n        content: messages.content,\n      })\n      .from(messages)\n      .where(eq(messages.chatId, chatId))\n      .orderBy(asc(messages.occurredOn))\n\n    return result.map((row) =&gt; row.content as CoreMessage)\n  }\n\n  async addMessage(chatId: number, content: CoreMessage): Promise&lt;void&gt; {\n    await database.insert(messages).values({\n      chatId,\n      content,\n    })\n  }\n\n  async clear(chatId: number): Promise&lt;void&gt; {\n    await database.delete(messages).where(eq(messages.chatId, chatId))\n  }\n}\n\nexport const conversationRepository = new ConversationRepository()\n</code></pre>"},{"location":"chatbot/memory/#step-4-implementing-memory-in-the-chatbot","title":"Step 4: Implementing Memory in the Chatbot","text":"<p>In this step, we enhance the chatbot's functionality by adding memory capabilities, allowing it to remember past interactions with users. This enables the bot to provide a more personalized experience and improve its responses based on previous messages.</p> <p>First we are going to reset the bot memory each time the <code>/start</code> command is executed, and add the welcome message.</p> src/lib/commands/start.ts<pre><code>import type { CommandContext, Context } from 'grammy'\n\nimport { conversationRepository } from '../repositories/conversation'\n\nexport async function start(context: CommandContext&lt;Context&gt;): Promise&lt;void&gt; {\n  const chatId = context.chat.id\n  // Clear the conversation\n  await conversationRepository.clear(chatId)\n\n  const content = 'Welcome, how can I help you?'\n  // Store the assistant's welcome message\n  await conversationRepository.addMessage(chatId, {\n    content,\n    role: 'assistant',\n  })\n\n  await context.reply(content)\n}\n</code></pre> <p>Now, we can add the user's messages and the bot's replies:</p> src/lib/handlers/on-message.ts<pre><code>import { generateText } from 'ai'\nimport { Composer } from 'grammy'\n\nimport { registry } from '../ai/setup-registry'\nimport { environment } from '../environment.mjs'\nimport { conversationRepository } from '../repositories/conversation'\n\nexport const onMessage = new Composer()\n\nconst PROMPT = `\nYou are a chatbot designed to help users book hair salon appointments for the next day.\n`\n\nonMessage.on('message:text', async (context) =&gt; {\n  const userMessage = context.message.text\n  const chatId = context.chat.id\n\n  // Store the user's message\n  await conversationRepository.addMessage(chatId, {\n    content: userMessage,\n    role: 'user',\n  })\n\n  // Retrieve past conversation history\n  const messages = await conversationRepository.get(chatId)\n\n  // Generate the assistant's response using the conversation history\n  const { responseMessages, text } = await generateText({\n    messages,\n    model: registry.languageModel(environment.MODEL),\n    system: PROMPT,\n  })\n\n  // Store the assistant's response\n  for await (const message of responseMessages) {\n    await conversationRepository.addMessage(chatId, message)\n  }\n\n  // Reply with the generated text\n  await context.reply(text)\n})\n</code></pre> <p>By incorporating memory, the bot becomes more capable of engaging in meaningful dialogues, improving user satisfaction and the overall chat experience.</p>"},{"location":"chatbot/ollama/","title":"Installing Ollama and Setting Up the Qwen2.5 Model","text":"<p>Info</p> <p>You can use free or commercial models. This tutorial includes both the possibility of using Ollama and OpenAI. You can add other providers if you wish, in the next chapter we explain how.</p>"},{"location":"chatbot/ollama/#what-is-ollama","title":"What is Ollama?","text":"<p>Ollama is a platform that allows developers to run language models locally or on remote servers. It provides a seamless way to integrate different AI models into your applications, making it easier to deploy large language models without relying entirely on cloud services. Ollama supports multiple models, and you can interact with them via its API.</p> <p>In this workshop, we are using Ollama as a provider to run the Qwen2.5 language model for generating responses. This model is specified in our environment configuration and will be used alongside Telegram to power the chatbot's AI capabilities.</p>"},{"location":"chatbot/ollama/#how-to-install-ollama","title":"How to Install Ollama","text":"<p>To install Ollama, follow these steps:</p> <ol> <li> <p>Download Ollama:    Visit the Ollama website and follow the instructions for your operating system (Linux, macOS, or Windows) to download the Ollama CLI (Command Line Interface).</p> </li> <li> <p>Install the CLI:    After downloading the installer for your platform, run the installation process. For example, on Linux, you can install Ollama using:</p> <pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre> </li> <li> <p>Verify Installation:    To check that Ollama is successfully installed, open your terminal and run:</p> <pre><code>ollama\n</code></pre> </li> </ol> <p>If the installation was successful, you should see a list of available commands and options for the Ollama CLI.</p>"},{"location":"chatbot/ollama/#installing-the-qwen25-model","title":"Installing the Qwen2.5 Model","text":"<p>Once Ollama is installed, you need to download the <code>qwen2.5</code> model to use it in your project. Follow these steps:</p> <ol> <li> <p>Pull the Model:    Run the following command to download the Qwen2.5 model:</p> <pre><code>ollama pull qwen2.5\n</code></pre> </li> <li> <p>Verify the Model:    After the model is downloaded, you can check that it's available by running:</p> <pre><code>ollama list\n</code></pre> </li> </ol> <p>This will display a list of all the installed models, including <code>qwen2.5</code>.</p>"},{"location":"chatbot/register/","title":"Creating Registries in Vercel SDK","text":"<p>In this section, you will learn how to create registries for AI models in Vercel SDK. This setup allows you to register multiple AI providers and language models to be used in your project.</p>"},{"location":"chatbot/register/#full-code","title":"Full code","text":"<p>Info</p> <p>This step is usually not necessary, if you are only going to use one AI provider you can use it directly instead of creating a record. For convenience, this code is already included in the template but we will explain it here.</p> src/lib/ai/setup-registry.ts<pre><code>import { openai as originalOpenAI } from '@ai-sdk/openai'\nimport {\n  experimental_createProviderRegistry as createProviderRegistry,\n  experimental_customProvider as customProvider,\n} from 'ai'\nimport { ollama as originalOllama } from 'ollama-ai-provider'\n\nconst ollama = customProvider({\n  fallbackProvider: originalOllama,\n  languageModels: {\n    'qwen-2_5': originalOllama('qwen2.5'),\n  },\n})\n\nexport const openai = customProvider({\n  fallbackProvider: originalOpenAI,\n  languageModels: {\n    'gpt-4o-mini': originalOpenAI('gpt-4o-mini', {\n      structuredOutputs: true,\n    }),\n  },\n})\n\nexport const registry = createProviderRegistry({\n  ollama,\n  openai,\n})\n</code></pre>"},{"location":"chatbot/register/#setting-up-the-registry","title":"Setting up the Registry","text":"<p>The following steps will guide you on how to register AI providers such as OpenAI and Ollama using the Vercel SDK. Open the file <code>src/lib/ai/setup-registry.ts</code> to see how it works.</p>"},{"location":"chatbot/register/#step-1-import-required-modules","title":"Step 1: Import Required Modules","text":"<p>First, import the necessary modules from the AI SDK and other providers:</p> <pre><code>import { openai as originalOpenAI } from '@ai-sdk/openai'\nimport {\n    experimental_createProviderRegistry as createProviderRegistry,\n    experimental_customProvider as customProvider,\n} from 'ai'\nimport { ollama as originalOllama } from 'ollama-ai-provider'\n</code></pre>"},{"location":"chatbot/register/#step-2-create-custom-providers","title":"Step 2: Create Custom Providers","text":"<p>Define custom providers for the AI models. For instance, we are using Ollama with a specific language model (<code>qwen-2_5</code>) and OpenAI with a custom model (<code>gpt-4o-mini</code>). Here is how you can define them:</p> <pre><code>const ollama = customProvider({\n    fallbackProvider: originalOllama,\n    languageModels: {\n    'qwen-2_5': originalOllama('qwen2.5'),\n    },\n})\n\nexport const openai = customProvider({\n    fallbackProvider: originalOpenAI,\n    languageModels: {\n    'gpt-4o-mini': originalOpenAI('gpt-4o-mini', {\n        structuredOutputs: true,\n    }),\n    },\n})\n</code></pre> <p>Info</p> <p>You can more models and providers if you wish. Just update the <code>MODEL*</code> envvars in <code>.env</code> file to activate them. If you need an API token you will need update the <code>src/lib/environment.mjs</code> file too.</p> <p>The model name should be <code>PROVIDER:MODEL_NAME</code> just like Ollama and OpenAI does.</p>"},{"location":"chatbot/register/#step-3-create-the-registry","title":"Step 3: Create the Registry","text":"<p>Once the providers are defined, create the registry that will include these custom providers:</p> <pre><code>export const registry = createProviderRegistry({\n    ollama,\n    openai,\n})\n</code></pre> <p>The <code>registry</code> now holds both Ollama and OpenAI providers, each registered with its specific language models.</p>"},{"location":"chatbot/register/#step-4-use-the-registry","title":"Step 4: Use the Registry","text":"<p>You can now use the <code>registry</code> in your project to manage and switch between AI providers and models as needed.</p> <p>This completes the setup for registering AI providers in the Vercel SDK. You can expand this registry by adding more providers or models as required by your application.</p> <p>Now, to use one or the other, edit the .env file and configure which provider and which model you want to use. Remember that if you want to use OpenAI you will have to have a Token API.</p> <p>Warning</p> <p>It is possible that the free models do not work as well as the proprietary ones in the examples that use tools. Especially if they are small, since it is normal that in local we cannot run models with more than 12B of parameters. After the publication of this tutorial new and better open models may appear, try other options to see if they work better. If not you can always try a commercial model.</p>"},{"location":"rag/basic/","title":"Data Augmentation Basics","text":"<p>Data augmentation is a technique used to enhance the performance of machine learning models by providing them with additional, relevant information. In the context of chatbots, particularly for specialized applications like booking hair salon appointments, data augmentation can significantly improve the quality of responses by enriching the context provided to the model.</p>"},{"location":"rag/basic/#implementing-basic-data-augmentation","title":"Implementing Basic Data Augmentation","text":"<p>To effectively implement data augmentation in our chatbot, we will utilize the <code>system</code> parameter in the <code>generateText</code> function. This parameter allows us to provide contextual information about the assistant's role and the relevant details about the business it represents.</p> <p>For our hair salon chatbot, we can define a <code>PROMPT</code> variable that includes both the assistant's role and essential details about the salon. Here's how you can set it up just updating the system prompt:</p> src/lib/handlers/on-message.ts (partial)<pre><code>const PROMPT = `\nYou are a chatbot designed to help users book hair salon appointments for the next day.\nHere is some basic information about the salon:\n- Services:\n  - Haircut: $25\n  - Hair Color: $50\n  - Manicure: $15\n- Opening Hours: Monday to Saturday, 9 AM to 7 PM\n- Closing Day: Sunday\n\nIf a user asks for information outside of these details, please respond with: \"I'm sorry, but I cannot assist with that. For more information, please call us at (555) 456-7890 or email us at info@hairsalon.example.com.\"\n`;\n\nconst { text } = await generateText({\n  messages,\n  model: registry.languageModel(environment.MODEL),\n  system: PROMPT,\n});\n</code></pre> <p>By enriching the model\u2019s understanding with specific information about the salon, we can ensure that it provides accurate answers related to services and availability. This is a straightforward method of implementing data augmentation, enhancing the user experience by making interactions more informative and context-aware.</p> <p>Example questions for the Chatbot</p> <p>You can try some of these questions to see how the bot responds now that you have provided it with more information:</p> <ul> <li>What services do you offer?</li> <li>What are your opening hours?</li> <li>How much is a haircut?</li> <li>Can I get a pedicure?</li> <li>What days are you open?</li> <li>Do you have any special promotions?</li> <li>Can I book an appointment for next week?</li> </ul>"},{"location":"rag/rag/","title":"Retrieval-Augmented Generation","text":"<p>RAG (Retrieval-Augmented Generation) is a technique that combines a language model with a retrieval system to enhance the model\u2019s responses. This method helps when the chatbot needs to provide specific information from external knowledge, such as documents or databases, that is not directly available in its training data. </p> <p>In our chatbot, we will use RAG to allow the bot to \u201clearn\u201d new information dynamically and then retrieve that information to answer user queries accurately. We\u2019ll be integrating two commands into the bot: /learn and /ask.</p>"},{"location":"rag/rag/#what-is-rag","title":"What is RAG?","text":"<p>RAG works by:</p> <ol> <li>Retrieving relevant information from an external source, like a database or documents.</li> <li>Augmenting a language model\u2019s prompt with this retrieved information to generate more accurate and context-aware responses.</li> </ol> <p>By splitting information into chunks and generating embeddings, we can compare the similarity of user queries with stored content. When a user asks a question, the system retrieves the most relevant content and uses it to improve the bot\u2019s answer.</p>"},{"location":"rag/rag/#what-are-embeddings","title":"What are Embeddings?","text":"<p>Embeddings are numerical representations of text that capture the meaning of words or sentences. In our case, embeddings allow us to represent pieces of content (e.g., text about services, pricing, or additional details) as vectors. By comparing the distance (e.g., cosine similarity) between these vectors and a user query\u2019s embedding, we can determine how similar the stored content is to the user\u2019s question.</p>"},{"location":"rag/rag/#creating-the-learn-command","title":"Creating the <code>/learn</code> command","text":"<p>The /learn command allows the chatbot to \u201clearn\u201d new content by generating embeddings for the input text and storing it in the database for later retrieval.</p> <p>Here\u2019s the code for <code>/learn</code>:</p> src/lib/commands/learn.ts<pre><code>import type { CommandContext, Context } from 'grammy'\n\nimport { createResource } from '../ai/resources'\n\nexport async function learn(context: CommandContext&lt;Context&gt;): Promise&lt;void&gt; {\n  const content = context.match\n\n  if (!content) {\n    await context.reply('No data found')\n    return\n  }\n\n  const response = await createResource({ content })\n  await context.reply(response)\n}\n</code></pre>"},{"location":"rag/rag/#creating-the-ask-command","title":"Creating the <code>/ask</code> command","text":"src/lib/commands/ask.ts<pre><code>import { generateText } from 'ai'\nimport type { CommandContext, Context } from 'grammy'\n\nimport { findRelevantContent } from '../ai/embeddings'\nimport { registry } from '../ai/setup-registry'\nimport { environment } from '../environment.mjs'\n\nexport async function ask(context: CommandContext&lt;Context&gt;): Promise&lt;void&gt; {\n  const userQuery = context.match\n\n  // Find relevant content using embeddings\n  const relevantContent = await findRelevantContent(userQuery)\n\n  if (relevantContent.length === 0) {\n    await context.reply(\"Sorry, I couldn't find any relevant information.\")\n    return\n  }\n\n  // Generate the response with the RAG-enhanced prompt\n  const { text } = await generateText({\n    messages: [{ content: userQuery, role: 'user' }],\n    model: registry.languageModel(environment.MODEL),\n    // Combine the relevant content into the system prompt\n    system: `\n      You are a chatbot designed to help users book hair salon appointments.\n      Here is some additional information relevant to your query:\n\n      ${relevantContent.map((content) =&gt; content.name).join('\\n')}\n\n      Answer the user's question based on this information.\n      If a user asks for information outside of these details, please respond with: \"I'm sorry, but I cannot assist with that. For more information, please call us at (555) 456-7890 or email us at info@hairsalon.com.\"\n    `,\n  })\n\n  // Reply with the generated text\n  await context.reply(text)\n}\n</code></pre>"},{"location":"rag/rag/#adding-the-new-commands","title":"Adding the new commands","text":"<p>Remember to add these two new commands to the bot so that they can be used:</p> src/main.ts<pre><code>import process from 'node:process'\n\nimport { Bot } from 'grammy'\n\nimport { ask } from './lib/commands/ask'\nimport { learn } from './lib/commands/learn'\nimport { start } from './lib/commands/start'\nimport { environment } from './lib/environment.mjs'\nimport { onMessage } from './lib/handlers/on-message'\n\nasync function main(): Promise&lt;void&gt; {\n  const bot = new Bot(environment.BOT_TOKEN)\n\n  bot.command('start', start)\n  bot.command('learn', learn)\n  bot.command('ask', ask)\n\n  bot.use(onMessage)\n\n  // Enable graceful stop\n  process.once('SIGINT', () =&gt; bot.stop())\n  process.once('SIGTERM', () =&gt; bot.stop())\n  process.once('SIGUSR2', () =&gt; bot.stop())\n\n  await bot.start()\n}\n\nmain().catch((error) =&gt; console.error(error))\n</code></pre> <p>How <code>createResource</code> and <code>findRelevantContent</code> works?</p> <p>The code of both functions are extracted from Vercel SDK AI RAG Guide. You can find a more extended description there, but basically this is the flow:</p> <ol> <li>Finding Relevant Content: The bot uses embeddings to compare the user\u2019s query to stored content in the database. The method findRelevantContent searches for the most similar chunks using cosine similarity. If the similarity score is above a certain threshold (in this case, 0.3), the content is considered relevant.</li> <li>Prompt Injection: Once the relevant content is found, it is combined into the PROMPT. This augmented prompt is passed into the generateText method, allowing the chatbot to provide an informed response based on the retrieved content.</li> <li>Generate Text with Custom Prompt: The generateText method now includes the additional content in the system prompt. This augments the bot\u2019s ability to respond in a contextually aware manner by incorporating specific information from the retrieved data.</li> </ol> <p>With RAG, our bot can learn new information dynamically and retrieve relevant content to enhance its responses. By leveraging embeddings and prompt injection, the bot becomes more capable of answering user questions accurately. This setup demonstrates how RAG can be applied to improve interactions, making the bot more flexible and intelligent while still being grounded in specific data sources.</p> <p>Exercise</p> <p>Add the information we had in the prompt:</p> <ol> <li><code>/learn Our salon offers a haircut service for $25.</code></li> <li><code>/learn Our salon provides hair color services for $50.</code></li> <li><code>/learn We also offer a manicure service for $15.</code></li> <li><code>/learn Our opening hours are Monday to Saturday from 9 AM to 7 PM.</code></li> <li><code>/learn Our salon is closed on Sundays.</code></li> </ol> <p>And them does some questions:</p> <ol> <li><code>/ask What are your opening hours?</code></li> <li><code>/ask How much is a haircut?</code></li> <li><code>/ask Say my name</code></li> </ol>"},{"location":"rag/tools/","title":"Dynamic Data Augmentation with Tools","text":"<p>In this section, we will enhance the chatbot\u2019s functionality by introducing dynamic Data Augmentation through external tools. Unlike the static information used in earlier sections, this approach enables the bot to fetch real-time data and perform actions that respond to changing contexts, such as booking appointments or checking availability. This allows the bot to adapt to different scenarios dynamically, offering more relevant and personalized responses to users.</p> <p>Warning</p> <p>For simplicity, we are using <code>chatId</code> instead of <code>userId</code>. Also, we are not handling concurrency or data integrity exceptions in this example.</p>"},{"location":"rag/tools/#step-1-create-the-appointments-table","title":"Step 1: Create the Appointments Table","text":"<p>This step involves defining the database schema for storing appointments, including a unique constraint to ensure that each time slot on a given day can only be reserved once. This schema serves as the foundation for the dynamic appointment scheduling system.</p> src/lib/db/schema/appointments.ts<pre><code>import {\n  bigint,\n  date,\n  pgTable,\n  serial,\n  time,\n  uniqueIndex,\n} from 'drizzle-orm/pg-core'\n\nexport const appointments = pgTable(\n  'appointments',\n  {\n    chatId: bigint('chat_id', { mode: 'number' }),\n    date: date('date', { mode: 'date' }).notNull(),\n    id: serial('id').primaryKey(),\n    timeSlot: time('time_slot').notNull(),\n  },\n  (table) =&gt; ({\n    // Unique constraint on date and time slot\n    uniqueDateTime: uniqueIndex('unique_date_time').on(\n      table.date,\n      table.timeSlot,\n    ),\n  }),\n)\n</code></pre> <p>Update the schema</p> <p>Remember to generate and execute the migrations just we did in the Adding Memory to the Bot section. </p>"},{"location":"rag/tools/#step-2-appointments-repository","title":"Step 2: Appointments Repository","text":"<p>The repository class contains methods for interacting with the database. It handles retrieving available appointments for a specified day and creating empty slots when none exist. The getFreeAppointmentsForDay method fetches all appointments for a given day and filters out the reserved ones (i.e., those with a chatId). If no appointments are found for the day, it dynamically creates them.</p> <p>This logic ensures that the chatbot can always return relevant appointment data, even if none have been pre-created for that day. The dynamic nature of this repository is key to making the system respond to real-world conditions.</p> src/lib/repositories/appointments.ts<pre><code>import { eq } from 'drizzle-orm/expressions'\n\nimport { db as database } from '../db/index'\nimport { appointments } from '../db/schema/appointments'\n\nexport class AppointmentRepository {\n  async getFreeAppointmentsForDay(\n    date: Date,\n  ): Promise&lt;Array&lt;{ timeSlot: string }&gt;&gt; {\n    const allAppointments = await database\n      .select({\n        chatId: appointments.chatId,\n        timeSlot: appointments.timeSlot,\n      })\n      .from(appointments)\n      .where(eq(appointments.date, date))\n\n    // If no appointments exist for this day, create them\n    if (allAppointments.length === 0) {\n      await this.createEmptyAppointmentsForDay(date)\n      return this.getFreeAppointmentsForDay(date)\n    }\n\n    // Filter free appointments where chatId is null (not reserved)\n    const freeAppointments = allAppointments.filter(\n      (appointment) =&gt; appointment.chatId === null,\n    )\n\n    return freeAppointments.map((appointment) =&gt; ({\n      timeSlot: appointment.timeSlot,\n    }))\n  }\n\n  private async createEmptyAppointmentsForDay(date: Date): Promise&lt;void&gt; {\n    const openingTime = 9 // 9 AM\n    const closingTime = 19 // 7 PM\n\n    const timeSlots = Array.from(\n      { length: closingTime - openingTime },\n      (_, index) =&gt; {\n        const time = `${(openingTime + index).toString().padStart(2, '0')}:00`\n        return { date, timeSlot: time }\n      },\n    )\n\n    // Insert empty appointments for each time slot\n    await database.insert(appointments).values(timeSlots)\n  }\n}\n\nexport const appointmentsRepository = new AppointmentRepository()\n</code></pre>"},{"location":"rag/tools/#step-3-creating-the-tool","title":"Step 3: Creating the tool","text":"<p>Here, we define a tool (getFreeAppointments) that fetches free appointments for the next day using the repository. The tool returns a markdown list of available time slots, which can be directly integrated into the chatbot\u2019s responses. This tool encapsulates the repository logic, ensuring that the chatbot can retrieve dynamic appointment data without direct interaction with the database.</p> src/lib/tools/get-free-appointments.ts<pre><code>import { type CoreTool, tool } from 'ai'\nimport { format } from 'date-fns'\nimport { z } from 'zod'\n\nimport { appointmentsRepository } from '../repositories/appointments'\nimport { tomorrow } from '../utils'\n\nexport const buildGetFreeAppointments = (): CoreTool =&gt;\n  tool({\n    description:\n      'Use this tool to search for available appointment times for tomorrow. Returns the response',\n    execute: async () =&gt; {\n      console.log(`Called getFreeAppointments tool`)\n\n      const freeAppointments =\n        await appointmentsRepository.getFreeAppointmentsForDay(tomorrow())\n\n      if (freeAppointments.length === 0) {\n        return `Sorry, there are no available appointments for tomorrow.`\n      }\n\n      const availableSlots = freeAppointments\n        .map(\n          (app) =&gt;\n            `- ${format(new Date(`1970-01-01T${app.timeSlot}`), 'HH:mm')}`,\n        )\n        .join('\\n')\n\n      return `Available appointments are:\\n${availableSlots}.`\n    },\n    parameters: z.object({}),\n  })\n</code></pre>"},{"location":"rag/tools/#step-4-adding-the-tool","title":"Step 4: Adding the tool","text":"<p>Finally we incorporate the tool to the context of our bot.</p> src/lib/handlers/on-message.ts<pre><code>import { generateText } from 'ai'\nimport { Composer } from 'grammy'\n\nimport { registry } from '../ai/setup-registry'\nimport { environment } from '../environment.mjs'\nimport { conversationRepository } from '../repositories/conversation'\nimport { buildGetFreeAppointments } from '../tools/get-free-appointments'\n\nexport const onMessage = new Composer()\n\nconst PROMPT = `\nYou are a chatbot designed to help users book hair salon appointments for the next day.\nIf the client ask for an appointment show the available slot times.\n\nUse the tool 'getFreeAppointments' if you need to search the available appointments for tomorrow.\n\nIf a user asks for information outside of these details, please respond with: \"I'm sorry, but I cannot assist with that. For more information, please call us at (555) 456-7890 or email us at info@hairsalon.com.\"\n`\n\nonMessage.on('message:text', async (context) =&gt; {\n  const userMessage = context.message.text\n  const chatId = context.chat.id\n\n  // Store the user's message\n  await conversationRepository.addMessage(chatId, {\n    content: userMessage,\n    role: 'user',\n  })\n\n  // Retrieve past conversation history\n  const messages = await conversationRepository.get(chatId)\n\n  // Generate the assistant's response using the conversation history\n  const { responseMessages, text } = await generateText({\n    maxSteps: 2,\n    messages,\n    model: registry.languageModel(environment.MODEL),\n    system: PROMPT,\n    tools: {\n      getFreeAppointments: buildGetFreeAppointments(),\n    },\n  })\n\n  // Store the assistant's response\n  for await (const message of responseMessages) {\n    await conversationRepository.addMessage(chatId, message)\n  }\n\n  // Reply with the generated text\n  await context.reply(text)\n})\n</code></pre> <p>By combining these tools and real-time data augmentation, the bot moves from being a static responder to a more interactive and context-aware assistant. This architecture allows for extending the bot with more tools in the future, enabling it to handle other types of dynamic data.</p>"}]}